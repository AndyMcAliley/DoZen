{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os,sys\n",
    "import string\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Proj, transform\n",
    "\n",
    "# avoid tkinter issue\n",
    "import matplotlib\n",
    "matplotlib.use('tkagg')\n",
    "\n",
    "# bokeh plotting\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure,show\n",
    "from bokeh.models.tools import HoverTool, TapTool\n",
    "from bokeh.models import CustomJS, ColumnDataSource, LabelSet\n",
    "from bokeh.tile_providers import get_provider, Vendors\n",
    "\n",
    "# pyviz\n",
    "import param\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from holoviews import opts, streams\n",
    "from holoviews.plotting.links import DataLink\n",
    "import hvplot.pandas\n",
    "\n",
    "#output_notebook()\n",
    "hv.notebook_extension('bokeh')\n",
    "pn.extension('vtk')\n",
    "\n",
    "# import DoZen\n",
    "# add parent directory to path\n",
    "try:\n",
    "    # works when called externally via panel serve\n",
    "    module_path = os.path.abspath(os.path.join(__file__,'..','..'))\n",
    "except NameError:\n",
    "    # works in notebook\n",
    "    module_path = str(Path().resolve().parent)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from dozen import z3d_directory, z3dio, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load campaign-specific variables from csv\n",
    "settings = pd.read_csv('timeline_settings.csv',index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get campaign from user\n",
    "choosing = True\n",
    "while(choosing):\n",
    "    print(settings.name)\n",
    "    t = input('Enter campaign index number: ')\n",
    "    try:\n",
    "        campaign_index = int(t)\n",
    "        campaign_name = settings.loc[campaign_index,'name']\n",
    "        print(campaign_name)\n",
    "        choosing = False\n",
    "    except ValueError:\n",
    "        print('Index must be a number')\n",
    "    except KeyError:\n",
    "        print('Index '+str(campaign_index)+' not found')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set campaign-specific variables\n",
    "campaign = settings.loc[campaign_index]\n",
    "rx_dir = campaign.rx_dir\n",
    "tx_dir = campaign.tx_dir\n",
    "location_file = campaign.rx_station_location_file\n",
    "min_end = pd.Timestamp(campaign.min_end,tz='US/Mountain')\n",
    "max_start = pd.Timestamp(campaign.max_start,tz='US/Mountain')\n",
    "min_easting = campaign.min_easting\n",
    "max_easting = campaign.max_easting\n",
    "min_northing = campaign.min_northing\n",
    "max_northing = campaign.max_northing\n",
    "utm_zone = campaign.utm_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read z3d directory info\n",
    "rx_full = z3d_directory.get_z3d_directory_info(initialdir=rx_dir,ask_dir=False)\n",
    "tx_full = z3d_directory.get_z3d_directory_info(initialdir=tx_dir,ask_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID duplicates\n",
    "rx_full['original'] = ~rx_full.duplicated(subset='filename',keep='first')\n",
    "tx_full['original'] = ~tx_full.duplicated(subset='filename',keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many z3d files are there?\n",
    "print('{} rx files'.format(len(rx_full)))\n",
    "# Count duplicated files\n",
    "print('{} duplicated rx files'.format((~rx_full.original).sum()))\n",
    "# Count invalid files\n",
    "print('{} invalid rx files'.format((~rx_full.valid).sum()))\n",
    "\n",
    "# Do the same for tx\n",
    "print('{} tx files'.format(len(tx_full)))\n",
    "print('{} duplicated tx files'.format((~tx_full.original).sum()))\n",
    "print('{} invalid tx files'.format((~tx_full.valid).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates, keeping only the first\n",
    "rx = rx_full.drop_duplicates(subset='filename',keep='first',inplace=False).copy()\n",
    "tx = tx_full.drop_duplicates(subset='filename',keep='first',inplace=False).copy()\n",
    "# drop invalid files\n",
    "rx.drop(rx[~rx.valid].index,inplace=True)\n",
    "tx.drop(tx[~tx.valid].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tx.loc[tx.iloc[[37,38]].index]\n",
    "tx_full.loc[tx.iloc[[37,38]].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID z3ds outside of date range\n",
    "def after_min_end(x):\n",
    "    try:\n",
    "        return x>min_end\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "def before_max_start(x):\n",
    "    try:\n",
    "        return x<max_start\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "rx_full['in_range'] = rx_full.end.apply(after_min_end) & rx_full.start.apply(before_max_start)\n",
    "tx_full['in_range'] = tx_full.end.apply(after_min_end) & tx_full.start.apply(before_max_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there old z3ds in this folder?\n",
    "print('{} rx files end before {}'.format((rx.end<min_end).sum(),min_end))\n",
    "print('{} rx files start after {}'.format((rx.start>max_start).sum(),max_start))\n",
    "\n",
    "# Do the same for tx\n",
    "print('{} tx files end before {}'.format((tx.end<min_end).sum(),min_end))\n",
    "print('{} tx files start after {}'.format((tx.start>max_start).sum(),max_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop files outside of specified date range\n",
    "rx.drop(rx[rx.end<min_end].index,inplace=True)\n",
    "tx.drop(tx[tx.end<min_end].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, what's left?\n",
    "print('{} rx files'.format(len(rx)))\n",
    "# Count duplicated files\n",
    "print('{} duplicated rx files'.format(rx.duplicated(subset='filename',keep='first').sum()))\n",
    "# Count invalid files\n",
    "print('{} invalid rx files'.format((~rx.valid).sum()))\n",
    "# Are there old z3ds in this folder?\n",
    "print('{} rx files end before {}'.format((rx.end<min_end).sum(),min_end))\n",
    "print('{} rx files start after {}'.format((rx.start>max_start).sum(),max_start))\n",
    "\n",
    "# Do the same for tx\n",
    "print('{} tx files'.format(len(tx)))\n",
    "print('{} duplicated tx files'.format(tx.duplicated(subset='filename',keep='first').sum()))\n",
    "print('{} invalid tx files'.format((~tx.valid).sum()))\n",
    "print('{} tx files end before {}'.format((tx.end<min_end).sum(),min_end))\n",
    "print('{} tx files start after {}'.format((tx.start>max_start).sum(),max_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind me, what are the fields in rx?\n",
    "rx.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get job number, station name, and run robustly, change this regex to suit your naming system\n",
    "parsed_job_number = pd.to_numeric(rx.job_number.str.replace(\"[^\\d-]\",\"\"),downcast='integer')\n",
    "parsed_station_folder = pd.to_numeric(rx.filepath.str.extract(r'/(?:BC|sub|Sub|SUB|LMA)(\\d+)[a-zA-Z]+/')[0])\n",
    "parsed_run = rx.job_number.astype(str).str[-1].fillna('')\n",
    "parsed_run = parsed_run.str.replace('\\d+','')\n",
    "parsed_station_name = rx.rx_station.astype(int).astype(str) + parsed_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx['parsed_run'] = parsed_run\n",
    "rx['parsed_station_name'] = parsed_station_name\n",
    "# compute web mercator coordinates\n",
    "utm_proj = Proj(proj=\"utm\",zone=utm_zone,ellps='WGS84')\n",
    "web_mercator = Proj(init='epsg:3857')\n",
    "rx['x_web_mercator'],rx['y_web_mercator'] = transform(utm_proj,web_mercator,rx.easting.values,rx.northing.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare full dataframes with dummy values\n",
    "rx_full['rx_station_qc'] = 0\n",
    "rx_full['run_qc'] = ''\n",
    "rx_full['easting_utm_qc'] = 0.0\n",
    "rx_full['northing_utm_qc'] = 0.0\n",
    "tx_full['rx_station_qc'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rx_station column using matplotlib\n",
    "#ax = rx.plot('easting','northing',kind='scatter')\n",
    "#for i,v in rx.iterrows():\n",
    "    #ax.text(v['easting'],v['northing'],v['rx_station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_hook(plot,element):\n",
    "    '''\n",
    "    Hook to use Bokeh for labels\n",
    "    Holoview's labels don't position correctly\n",
    "    '''\n",
    "    rcsource = ColumnDataSource(rx)\n",
    "    station_labels = LabelSet(x='x_web_mercator',y='y_web_mercator',text='parsed_station_name',source=rcsource)\n",
    "    plot.handles['plot'].add_layout(station_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx_locations = rx.hvplot.scatter(x='x_web_mercator',\n",
    "                                 y='y_web_mercator',\n",
    "                                 padding=0.2,\n",
    "                                 selection_color='red'\n",
    "                                )\n",
    "sel = streams.Selection1D(source=rx_locations)\n",
    "\n",
    "dtools = ['save','pan','box_zoom','reset']\n",
    "stools = ['lasso_select']\n",
    "base_map = hv.element.tiles.StamenTerrain()\n",
    "hvp = (base_map*rx_locations).opts(\n",
    "#hvp = (rx_locations).opts(\n",
    "    opts.Scatter(default_tools=dtools,\n",
    "                 tools=stools,\n",
    "                 active_tools=stools,\n",
    "                 hooks=[label_hook],\n",
    "                 width=600,\n",
    "                 height=400),\n",
    "    opts.Tiles(default_tools=dtools),\n",
    "    opts.Table(editable=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_label_hook(plot,element):\n",
    "    '''\n",
    "    Hook to use Bokeh for labels\n",
    "    Holoview's labels don't position correctly\n",
    "    '''\n",
    "    \n",
    "    #parsed_run = rx.job_number.astype(str).str[-1]\n",
    "    #parsed_run = parsed_run.str.replace('\\d+','')\n",
    "    #parsed_station_name = rx.rx_station.astype(int).astype(str) + parsed_run\n",
    "    \n",
    "    station_name = rxla.averaged_points.rx_station\n",
    "    run = rxla.averaged_points.run.astype(str).str.replace('Do not change','')\n",
    "    rxla.averaged_points['station_name'] = station_name + run\n",
    "    rcsource = ColumnDataSource(rxla.averaged_points)\n",
    "    station_labels = LabelSet(x='x_web_mercator',y='y_web_mercator',text='station_name',source=rcsource,text_color='green')\n",
    "    plot.handles['plot'].add_layout(station_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RX_Location_Averager(param.Parameterized):\n",
    "    '''\n",
    "    Let's do this\n",
    "    '''\n",
    "    station_number = param.Integer(default=0)\n",
    "    station_run = param.Selector(default='Do not change',objects=['Do not change','a','b','c','d','e','f','g'])\n",
    "    \n",
    "    #guess_station_number = param.Action(lambda x: x.guess_station_number_from_selected(), label='Guess station number')\n",
    "    add_to_list = param.Action(lambda x: x.add_selected_to_list(), label='Add to list')\n",
    "    remove_from_list = param.Action(lambda x: x.remove_selected_from_list(), label='Remove from list')\n",
    "    # hidden parameter for updating plot and table\n",
    "    _update_view = param.Action(lambda x: x.param.trigger('_update_view'), \n",
    "                                label='Update view', \n",
    "                                precedence=-1)\n",
    "    \n",
    "    averaged_points = pd.DataFrame({'x_web_mercator':[],\n",
    "                                    'y_web_mercator':[],\n",
    "                                    'rx_station':[],\n",
    "                                    'run':[],\n",
    "                                    'station_name':[]})\n",
    "    \n",
    "    def add_selected_to_list(self):\n",
    "        '''\n",
    "        triggered when \"Add to list\" button is clicked\n",
    "        Computes an average location from selected points\n",
    "        '''\n",
    "        x_avg = rx['x_web_mercator'].iloc[sel.index].mean()\n",
    "        y_avg = rx['y_web_mercator'].iloc[sel.index].mean()\n",
    "        this_rx_station = str(self.station_number)\n",
    "        this_run = self.station_run\n",
    "        new_location = pd.DataFrame({'x_web_mercator':[x_avg],\n",
    "                                     'y_web_mercator':[y_avg],\n",
    "                                     'rx_station':[this_rx_station],\n",
    "                                     'run':[this_run],\n",
    "                                     'station_name':[this_rx_station+this_run],\n",
    "                                     'full_indeces':[rx.iloc[sel.index].index]})\n",
    "        if not (np.isnan(x_avg) or np.isnan(y_avg)):\n",
    "            self.averaged_points = self.averaged_points.append(new_location,ignore_index=True,sort=False)\n",
    "        self.param.trigger('_update_view')\n",
    "    \n",
    "    def remove_selected_from_list(self):\n",
    "        '''\n",
    "        triggered when \"Remove from list\" button is clicked\n",
    "        removes selected location from table\n",
    "        '''\n",
    "        idx = self.averaged_points.index[self.table_selection.index]\n",
    "        new_df = self.averaged_points.drop(self.averaged_points.index[self.table_selection.index],inplace=False)\n",
    "        self.averaged_points = new_df\n",
    "        self.param.trigger('_update_view')\n",
    "        \n",
    "    \n",
    "    @param.depends('_update_view')\n",
    "    def averaged_points_plot(self):\n",
    "        '''\n",
    "        plot averaged points in green,\n",
    "        overlayed on all points (hvp)\n",
    "        '''\n",
    "        avp = self.averaged_points.hvplot.scatter(\n",
    "            x='x_web_mercator',\n",
    "            y='y_web_mercator',\n",
    "            padding=0.2,\n",
    "            color='green',\n",
    "            tools=[]\n",
    "        ).opts(\n",
    "            opts.Scatter(default_tools=dtools,\n",
    "                         tools=[],\n",
    "                         hooks=[averaged_label_hook])\n",
    "        )\n",
    "        return (hvp*avp).opts(opts.Tiles(default_tools=dtools),\n",
    "                              opts.Scatter(default_tools=dtools))\n",
    "    \n",
    "    @param.depends('_update_view')\n",
    "    def averaged_points_table(self):\n",
    "        '''\n",
    "        table of averaged points\n",
    "        '''\n",
    "        table = hv.Table(self.averaged_points,\n",
    "                         ['x_web_mercator','y_web_mercator'],\n",
    "                         ['rx_station','run']).opts(\n",
    "        opts.Table(editable=True,height=600)\n",
    "        )\n",
    "        self.table_selection = streams.Selection1D(source=table)\n",
    "        return table\n",
    "    \n",
    "    def guess_station_number_from_selected(self,index=0):\n",
    "        '''\n",
    "        triggered when \"Guess station number\" button is clicked,\n",
    "        or when lasso selection changes\n",
    "        Populates station number from selected points\n",
    "        '''\n",
    "        try:\n",
    "            station_number = rx['rx_station'].iloc[sel.index].mode()[0]\n",
    "            if type(station_number) != int:\n",
    "                station_number = int(station_number)\n",
    "            self.station_number = station_number\n",
    "        except:\n",
    "            station_number = 0\n",
    "        try:\n",
    "            job_letter = rx['job_number'].iloc[sel.index].mode()[0]\n",
    "            run = job_letter[-1]\n",
    "            #self.station_run = run\n",
    "        except:\n",
    "            run = self.param.station_run.objects[-1]\n",
    "            \n",
    "    #@param.depends('save_csv')\n",
    "    def save_locations_as_csv(self,e):\n",
    "        filename = util.savefile(title='Save locations file',initialdir=str(Path.cwd()))\n",
    "        avp = self.averaged_points\n",
    "        # compute utm coordinates\n",
    "        avp['x_utm'],avp['y_utm'] = transform(web_mercator,utm_proj,avp.x_web_mercator.values,avp.y_web_mercator.values)\n",
    "        avp.to_csv(filename)\n",
    "    \n",
    "    def save_full_as_csv(self,e):\n",
    "        '''\n",
    "        save rx_full and tx_full dataframes as csv files\n",
    "        '''\n",
    "        filename = util.savefile(title='Save z3d metadata files',initialdir=str(Path.cwd()))\n",
    "        if filename:\n",
    "            # save station number and run to full dataframes for posterity\n",
    "            rx_full_write = rx_full.copy()\n",
    "            avp = self.averaged_points\n",
    "            # compute utm coordinates\n",
    "            avp['x_utm'],avp['y_utm'] = transform(web_mercator,\n",
    "                                                  utm_proj,\n",
    "                                                  avp.x_web_mercator.values,\n",
    "                                                  avp.y_web_mercator.values)\n",
    "            \n",
    "            # apply properties to all pertinent rows\n",
    "            for avp_row in avp.itertuples(index=False):\n",
    "                full_indeces = avp_row.full_indeces\n",
    "                rx_full_write.loc[full_indeces,'rx_station_qc'] = int(avp_row.rx_station)\n",
    "                if avp_row.run == 'Do not change':\n",
    "                    rx_full_write.loc[full_indeces,'run_qc'] = rx.loc[full_indeces,'parsed_run']\n",
    "                else:\n",
    "                    rx_full_write.loc[full_indeces,'run_qc'] = avp_row.run\n",
    "                rx_full_write.loc[full_indeces,'easting_utm_qc'] = avp_row.x_utm\n",
    "                rx_full_write.loc[full_indeces,'northing_utm_qc'] = avp_row.y_utm\n",
    "            rx_full_write.to_csv(filename+'_rx.csv')\n",
    "            tx_full.to_csv(filename+'_tx.csv')\n",
    "        \n",
    "    def panel(self):\n",
    "        return pn.Row(pn.Column(self.param,self.averaged_points_plot),self.averaged_points_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxla = RX_Location_Averager()\n",
    "sel.add_subscriber(rxla.guess_station_number_from_selected)\n",
    "save_locations = pn.widgets.Button(name='Save locations')\n",
    "save_full = pn.widgets.Button(name='Save z3d metadata')\n",
    "save_locations.on_click(rxla.save_locations_as_csv)\n",
    "save_full.on_click(rxla.save_full_as_csv)\n",
    "pn.Column(rxla.panel(),pn.Row(save_locations,save_full)).servable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dozen",
   "language": "python",
   "name": "dozen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
